{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "MujocoDependencyError",
     "evalue": "To use MuJoCo, you need to either populate ~/.mujoco/mjkey.txt and ~/.mujoco/mjpro131, or set the MUJOCO_PY_MJKEY_PATH and MUJOCO_PY_MJPRO_PATH environment variables appropriately. Follow the instructions on https://github.com/openai/mujoco-py for where to obtain these.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMujocoDependencyError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgymnasium\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInvertedPendulum-v4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shani\\miniconda3\\envs\\gym\\Lib\\site-packages\\gymnasium\\envs\\registration.py:756\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    753\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m env_spec\u001b[38;5;241m.\u001b[39mentry_point\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Assume it's a string\u001b[39;00m\n\u001b[1;32m--> 756\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m \u001b[43mload_env_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_point\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;66;03m# Determine if to use the rendering\u001b[39;00m\n\u001b[0;32m    759\u001b[0m render_modes: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shani\\miniconda3\\envs\\gym\\Lib\\site-packages\\gymnasium\\envs\\registration.py:545\u001b[0m, in \u001b[0;36mload_env_creator\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an environment with name of style ``\"(import path):(environment name)\"`` and returns the environment creation function, normally the environment class type.\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \n\u001b[0;32m    538\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m    The environment constructor for the given environment name.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m mod_name, attr_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 545\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, attr_name)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[1;32mc:\\Users\\shani\\miniconda3\\envs\\gym\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1310\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:994\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\shani\\miniconda3\\envs\\gym\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MujocoEnv, MuJocoPyEnv  \u001b[38;5;66;03m# isort:skip\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ^^^^^ so that user gets the correct error\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# message if mujoco is not installed correctly\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AntEnv\n",
      "File \u001b[1;32mc:\\Users\\shani\\miniconda3\\envs\\gym\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_env.py:13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Space\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmujoco_py\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     15\u001b[0m     MUJOCO_PY_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[1;32mc:\\Users\\shani\\miniconda3\\envs\\gym\\Lib\\site-packages\\mujoco_py\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_config, get_key_path\n\u001b[1;32m----> 2\u001b[0m \u001b[43minit_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmjviewer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MjViewer\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmjcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MjModel\n",
      "File \u001b[1;32mc:\\Users\\shani\\miniconda3\\envs\\gym\\Lib\\site-packages\\mujoco_py\\config.py:33\u001b[0m, in \u001b[0;36minit_config\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     mjpro_path \u001b[38;5;241m=\u001b[39m default_mjpro_path\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _key_path \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mjpro_path:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mMujocoDependencyError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo use MuJoCo, you need to either populate ~/.mujoco/mjkey.txt and ~/.mujoco/mjpro131, or set the MUJOCO_PY_MJKEY_PATH and MUJOCO_PY_MJPRO_PATH environment variables appropriately. Follow the instructions on https://github.com/openai/mujoco-py for where to obtain these.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _key_path:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mMujocoDependencyError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound your MuJoCo binaries but not license key. Please put your key into ~/.mujoco/mjkey.txt or set MUJOCO_PY_MJKEY_PATH. Follow the instructions on https://github.com/openai/mujoco-py for setup.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mMujocoDependencyError\u001b[0m: To use MuJoCo, you need to either populate ~/.mujoco/mjkey.txt and ~/.mujoco/mjpro131, or set the MUJOCO_PY_MJKEY_PATH and MUJOCO_PY_MJPRO_PATH environment variables appropriately. Follow the instructions on https://github.com/openai/mujoco-py for where to obtain these."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import gymnasium\n",
    "\n",
    "\n",
    "env = gymnasium.make('InvertedPendulum-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Actor-Critic Network for Continuous Action Spaces\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(state_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, action_dim)\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.zeros(action_dim))  # Learnable log standard deviation\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(state_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = self.actor(x)\n",
    "        std = self.log_std.exp().expand_as(mean)  # Standard deviation\n",
    "        dist = torch.distributions.Normal(mean, std)\n",
    "        return dist, self.critic(x)\n",
    "\n",
    "# PPO Agent with Clipping Method\n",
    "class PPOAgent:\n",
    "    def __init__(self, state_dim, action_dim, lr=3e-4, clip_epsilon=0.2):\n",
    "        self.model = ActorCritic(state_dim, action_dim)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.gamma = 0.99\n",
    "        self.clip_epsilon = clip_epsilon\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        dist, _ = self.model(state_tensor)\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "        return action.item(), log_prob.item()\n",
    "\n",
    "    def train(self, states, actions, rewards, next_states, dones, old_log_probs):\n",
    "        states_tensor = torch.FloatTensor(states)\n",
    "        actions_tensor = torch.FloatTensor(actions).unsqueeze(1)\n",
    "        next_states_tensor = torch.FloatTensor(next_states)\n",
    "        rewards_tensor = torch.FloatTensor(rewards)\n",
    "        dones_tensor = torch.FloatTensor(dones)\n",
    "        old_log_probs_tensor = torch.FloatTensor(old_log_probs)\n",
    "\n",
    "        _, values = self.model(states_tensor)\n",
    "        dists, next_values = self.model(next_states_tensor)\n",
    "\n",
    "        new_log_probs = dists.log_prob(actions_tensor).sum(axis=1, keepdim=True)\n",
    "\n",
    "        advantages = rewards_tensor + self.gamma * next_values.squeeze() * (1 - dones_tensor) - values.squeeze()\n",
    "\n",
    "        ratios = (new_log_probs - old_log_probs_tensor).exp()\n",
    "        clipped_ratios = torch.clamp(ratios, 1 - self.clip_epsilon, 1 + self.clip_epsilon)\n",
    "        surrogate_loss = -torch.min(ratios * advantages, clipped_ratios * advantages).mean()\n",
    "\n",
    "        critic_loss = advantages.pow(2).mean()\n",
    "        loss = surrogate_loss + critic_loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "# Training Function\n",
    "def train_agent(agent, env, episodes=1000):\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()[0]\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        states, actions, rewards, next_states, dones, old_log_probs = [], [], [], [], [], []\n",
    "\n",
    "        while not done:\n",
    "            action, log_prob = agent.select_action(state)\n",
    "            next_state, reward, done, _,_ = env.step([action])  # Action needs to be a list\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(next_state)\n",
    "            dones.append(done)\n",
    "            old_log_probs.append(log_prob)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "        agent.train(states, actions, rewards, next_states, dones, old_log_probs)\n",
    "        print(f'Episode {episode + 1}: Total Reward: {total_reward}')\n",
    "\n",
    "env = gymnasium.make('InvertedPendulum-v4')\n",
    "agent = PPOAgent(state_dim=env.observation_space.shape[0], action_dim=env.action_space.shape[0])\n",
    "train_agent(agent, env, episodes=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(agent, env, episodes=10):\n",
    "    total_rewards = []\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()[0]\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = agent.select_action(state)  # Use the trained policy to select actions\n",
    "            state, reward, done, _ , _= env.step([action])  # Action should be in the correct format\n",
    "            total_reward += reward\n",
    "        total_rewards.append(total_reward)\n",
    "        print(f'Evaluation Episode {episode + 1}: Total Reward: {total_reward}')\n",
    "    \n",
    "    average_reward = sum(total_rewards) / len(total_rewards)\n",
    "    print(f'Average Reward over {episodes} episodes: {average_reward}')\n",
    "    return average_reward\n",
    "\n",
    "env = gymnasium.make('InvertedPendulum-v4', render_mode='human')\n",
    "\n",
    "evaluate_policy(agent, env, episodes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
