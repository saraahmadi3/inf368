{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "env = gymnasium.make('MountainCar-v0', max_episode_steps = 1000)\n",
    "# car moving along a line, the x-axis, between two \"mountains\"\n",
    "# the car has to reach the flag at the top of the right mountain\n",
    "# the car has to build momentum by driving back and forth between the mountains\n",
    "# the car has to reach the flag before the episode ends\n",
    "# https://gymnasium.farama.org/environments/classic_control/mountain_car/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2       , -1.10526316, -1.01052632, -0.91578947, -0.82105263,\n",
       "       -0.72631579, -0.63157895, -0.53684211, -0.44210526, -0.34736842,\n",
       "       -0.25263158, -0.15789474, -0.06315789,  0.03157895,  0.12631579,\n",
       "        0.22105263,  0.31578947,  0.41052632,  0.50526316,  0.6       ])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.linspace(-1.2, 0.6, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.47260767,  0.        ], dtype=float32), {})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset(seed=SEED) # must reset before using step\n",
    "# from the gym documentation:\n",
    "# start position is uniformly random value between -0.6 and -0.4\n",
    "# start velocity is 0\n",
    "# use seed to make the start position deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position Bounds: (-1.2, 0.6)\n",
      "Velocity Bounds: (-0.07, 0.07)\n"
     ]
    }
   ],
   "source": [
    "# Get the bounds for position and velocity\n",
    "position_bounds = (env.observation_space.low[0], env.observation_space.high[0])\n",
    "velocity_bounds = (env.observation_space.low[1], env.observation_space.high[1])\n",
    "\n",
    "# Define the state bounds\n",
    "STATE_BOUNDS = [position_bounds, velocity_bounds]\n",
    "\n",
    "print(\"Position Bounds:\", position_bounds)\n",
    "print(\"Velocity Bounds:\", velocity_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose discrete step delta for position and velocity\n",
    "# to discretize the state space\n",
    "delta_position = 0.1\n",
    "delta_velocity = 0.01\n",
    "\n",
    "DELTA = [delta_position, delta_velocity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NUM_BINS**\n",
    "- decide the number of bins for each state value\n",
    "- decides the *granularity* or *resulotion* of the state space\n",
    "\n",
    "- the more bins, the more states, the finer resolution and capture more details of the state space\n",
    "- but also increases the size of the Q-table, and the time to train the agent\n",
    "\n",
    "\n",
    "- the fewer bins, the fewer states, the coarser resolution and capture less details of the state space\n",
    "- but also decreases the size of the Q-table, and the time to train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 1]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the number of bins for position and velocity based on the bounds and delta\n",
    "NUM_BINS = [int(STATE_BOUNDS[i][1] - STATE_BOUNDS[i][0] / DELTA[i])+1 for i in range(2)]\n",
    "NUM_BINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "actions = env.action_space\n",
    "print(actions)\n",
    "# so actions are 0, 1, 2\n",
    "# 0 = accelerate to the left\n",
    "# 1 = don't accelerate\n",
    "# 2 = accelerate to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.47674024, -0.00275165], dtype=float32), -1.0, False, False, {})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notes for myself\n",
    "# state is a tuple of 2 floats (position, velocity)\n",
    "# reward is a float (negative for each time step) and 0 at the end (i assume)\n",
    "# terminated if find end goal\n",
    "# turnicated if reach max_episode_steps or something else\n",
    "# info is a dictionary containing extra information about the environment: here nothing\n",
    "state, reward, terminated, turnicated,info = env.step(0)\n",
    "# hence 2 ways to be done\n",
    "done = terminated or turnicated\n",
    "\n",
    "env.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so discretize the state: \n",
    "\n",
    "from:\n",
    "\n",
    "&emsp;combination of x poistion and velocity as floats\n",
    "\n",
    "into:\n",
    "\n",
    "&emsp;(x,v) where 0<=x<= NUM_BINS[0] and 0<=x<= NUM_BINS[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 9)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discretize the state space\n",
    "def discretize_state(state):\n",
    "    discretized_state = []\n",
    "    for i in range(len(state)):\n",
    "        lower_bound, upper_bound = STATE_BOUNDS[i]\n",
    "        # make sure the state is within the bounds\n",
    "        # above the lower bound and below the upper bound\n",
    "        value = min(max(state[i], lower_bound), upper_bound)\n",
    "        # discretize the value --> from foat to int\n",
    "        discretized_value = int((value - lower_bound) / (upper_bound - lower_bound) * NUM_BINS[i])\n",
    "        discretized_state.append(discretized_value)\n",
    "    return tuple(discretized_state)\n",
    "discretize_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf368",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
